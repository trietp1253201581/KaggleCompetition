{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Notebook này chạy trên local."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Binary Classification with a Bank Churn Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Link_to_competition](https://www.kaggle.com/competitions/playground-series-s4e1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exploring datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['KAGGLE_CONFIG_DIR'] = '.'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "playground-series-s4e1.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
     ]
    }
   ],
   "source": [
    "!kaggle competitions download -c playground-series-s4e1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from zipfile import ZipFile\n",
    "with ZipFile('playground-series-s4e1.zip') as f:\n",
    "    f.extractall('bank-churn-data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = pd.read_csv('bank-churn-data/train.csv')\n",
    "test_df = pd.read_csv('bank-churn-data/test.csv')\n",
    "sub_df = pd.read_csv('bank-churn-data/sample_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>15674932</td>\n",
       "      <td>Okwudilichukwu</td>\n",
       "      <td>668</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>181449.97</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>15749177</td>\n",
       "      <td>Okwudiliolisa</td>\n",
       "      <td>627</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>49503.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>15694510</td>\n",
       "      <td>Hsueh</td>\n",
       "      <td>678</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>40.0</td>\n",
       "      <td>10</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>184866.69</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>15741417</td>\n",
       "      <td>Kao</td>\n",
       "      <td>581</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>34.0</td>\n",
       "      <td>2</td>\n",
       "      <td>148882.54</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>84560.88</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>15766172</td>\n",
       "      <td>Chiemenam</td>\n",
       "      <td>716</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>33.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15068.83</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165029</th>\n",
       "      <td>165029</td>\n",
       "      <td>15667085</td>\n",
       "      <td>Meng</td>\n",
       "      <td>667</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>33.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>131834.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165030</th>\n",
       "      <td>165030</td>\n",
       "      <td>15665521</td>\n",
       "      <td>Okechukwu</td>\n",
       "      <td>792</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>131834.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165031</th>\n",
       "      <td>165031</td>\n",
       "      <td>15664752</td>\n",
       "      <td>Hsia</td>\n",
       "      <td>565</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>127429.56</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165032</th>\n",
       "      <td>165032</td>\n",
       "      <td>15689614</td>\n",
       "      <td>Hsiung</td>\n",
       "      <td>554</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>30.0</td>\n",
       "      <td>7</td>\n",
       "      <td>161533.00</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71173.03</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>165033</th>\n",
       "      <td>165033</td>\n",
       "      <td>15732798</td>\n",
       "      <td>Ulyanov</td>\n",
       "      <td>850</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>31.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>61581.79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>165034 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            id  CustomerId         Surname  CreditScore Geography  Gender  \\\n",
       "0            0    15674932  Okwudilichukwu          668    France    Male   \n",
       "1            1    15749177   Okwudiliolisa          627    France    Male   \n",
       "2            2    15694510           Hsueh          678    France    Male   \n",
       "3            3    15741417             Kao          581    France    Male   \n",
       "4            4    15766172       Chiemenam          716     Spain    Male   \n",
       "...        ...         ...             ...          ...       ...     ...   \n",
       "165029  165029    15667085            Meng          667     Spain  Female   \n",
       "165030  165030    15665521       Okechukwu          792    France    Male   \n",
       "165031  165031    15664752            Hsia          565    France    Male   \n",
       "165032  165032    15689614          Hsiung          554     Spain  Female   \n",
       "165033  165033    15732798         Ulyanov          850    France    Male   \n",
       "\n",
       "         Age  Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0       33.0       3       0.00              2        1.0             0.0   \n",
       "1       33.0       1       0.00              2        1.0             1.0   \n",
       "2       40.0      10       0.00              2        1.0             0.0   \n",
       "3       34.0       2  148882.54              1        1.0             1.0   \n",
       "4       33.0       5       0.00              2        1.0             1.0   \n",
       "...      ...     ...        ...            ...        ...             ...   \n",
       "165029  33.0       2       0.00              1        1.0             1.0   \n",
       "165030  35.0       3       0.00              1        0.0             0.0   \n",
       "165031  31.0       5       0.00              1        1.0             1.0   \n",
       "165032  30.0       7  161533.00              1        0.0             1.0   \n",
       "165033  31.0       1       0.00              1        1.0             0.0   \n",
       "\n",
       "        EstimatedSalary  Exited  \n",
       "0             181449.97       0  \n",
       "1              49503.50       0  \n",
       "2             184866.69       0  \n",
       "3              84560.88       0  \n",
       "4              15068.83       0  \n",
       "...                 ...     ...  \n",
       "165029        131834.75       0  \n",
       "165030        131834.45       0  \n",
       "165031        127429.56       0  \n",
       "165032         71173.03       0  \n",
       "165033         61581.79       1  \n",
       "\n",
       "[165034 rows x 14 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "id                 0\n",
       "CustomerId         0\n",
       "Surname            0\n",
       "CreditScore        0\n",
       "Geography          0\n",
       "Gender             0\n",
       "Age                0\n",
       "Tenure             0\n",
       "Balance            0\n",
       "NumOfProducts      0\n",
       "HasCrCard          0\n",
       "IsActiveMember     0\n",
       "EstimatedSalary    0\n",
       "Exited             0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def view_categoricals_feature(cat_col: str):\n",
    "    total = raw_df[cat_col].value_counts()\n",
    "    zeros = raw_df[raw_df['Exited']==0][cat_col].value_counts()\n",
    "    return zeros/total*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Geography\n",
       "France     83.471846\n",
       "Spain      82.782426\n",
       "Germany    62.104837\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_categoricals_feature('Geography')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Gender\n",
       "Male      84.094471\n",
       "Female    72.031328\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_categoricals_feature('Gender')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "HasCrCard\n",
       "1.0    79.356736\n",
       "0.0    77.257056\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_categoricals_feature('HasCrCard')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IsActiveMember\n",
       "0.0    70.291368\n",
       "1.0    87.465459\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_categoricals_feature('IsActiveMember')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    165034.000000\n",
       "mean         38.125888\n",
       "std           8.867205\n",
       "min          18.000000\n",
       "25%          32.000000\n",
       "50%          37.000000\n",
       "75%          42.000000\n",
       "max          92.000000\n",
       "Name: Age, dtype: float64"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df['Age'].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df['AgeGroup'] = pd.cut(raw_df['Age'],\n",
    "                            bins=[17,30,60,100],\n",
    "                            labels=['Adult','OldAdult','Old'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df['AgeGroup'] = pd.cut(test_df['Age'],\n",
    "                             bins=[17,30,60,100],\n",
    "                             labels=['Adult','OldAdult','Old'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AgeGroup\n",
       "OldAdult    76.335046\n",
       "Adult       91.735079\n",
       "Old         68.575697\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_categoricals_feature('AgeGroup')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NumOfProducts\n",
       "2    93.957837\n",
       "1    65.288081\n",
       "3    11.748445\n",
       "4    12.421053\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_categoricals_feature('NumOfProducts')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Tenure\n",
       "0     74.515678\n",
       "1     77.386635\n",
       "2     80.515378\n",
       "3     77.089597\n",
       "4     77.361285\n",
       "5     77.993977\n",
       "6     80.122614\n",
       "7     81.240876\n",
       "8     80.205479\n",
       "9     78.789874\n",
       "10    78.727365\n",
       "Name: count, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "view_categoricals_feature('Tenure')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "numeric_cols = ['CreditScore','Tenure','Balance','NumOfProducts','EstimatedSalary']\n",
    "categorical_cols = ['AgeGroup','Geography','Gender','HasCrCard','IsActiveMember']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler, OneHotEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler().fit(raw_df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df[numeric_cols] = scaler.transform(raw_df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_df[numeric_cols] = scaler.transform(test_df[numeric_cols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>165034.000000</td>\n",
       "      <td>165034.000000</td>\n",
       "      <td>165034.000000</td>\n",
       "      <td>165034.000000</td>\n",
       "      <td>165034.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.612909</td>\n",
       "      <td>0.502035</td>\n",
       "      <td>0.221118</td>\n",
       "      <td>0.184818</td>\n",
       "      <td>0.562870</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.160207</td>\n",
       "      <td>0.280616</td>\n",
       "      <td>0.250371</td>\n",
       "      <td>0.182385</td>\n",
       "      <td>0.251488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.494000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.373166</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.618000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.589738</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.478041</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.775779</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CreditScore         Tenure        Balance  NumOfProducts  \\\n",
       "count  165034.000000  165034.000000  165034.000000  165034.000000   \n",
       "mean        0.612909       0.502035       0.221118       0.184818   \n",
       "std         0.160207       0.280616       0.250371       0.182385   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.494000       0.300000       0.000000       0.000000   \n",
       "50%         0.618000       0.500000       0.000000       0.333333   \n",
       "75%         0.720000       0.700000       0.478041       0.333333   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       EstimatedSalary  \n",
       "count    165034.000000  \n",
       "mean          0.562870  \n",
       "std           0.251488  \n",
       "min           0.000000  \n",
       "25%           0.373166  \n",
       "50%           0.589738  \n",
       "75%           0.775779  \n",
       "max           1.000000  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_df[numeric_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>110023.000000</td>\n",
       "      <td>110023.000000</td>\n",
       "      <td>110023.000000</td>\n",
       "      <td>110023.000000</td>\n",
       "      <td>110023.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>0.613062</td>\n",
       "      <td>0.499664</td>\n",
       "      <td>0.220542</td>\n",
       "      <td>0.184440</td>\n",
       "      <td>0.561571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>0.160631</td>\n",
       "      <td>0.280615</td>\n",
       "      <td>0.250255</td>\n",
       "      <td>0.181571</td>\n",
       "      <td>0.251409</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.494000</td>\n",
       "      <td>0.300000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.372179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>0.620000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.589160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>0.720000</td>\n",
       "      <td>0.700000</td>\n",
       "      <td>0.478862</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.773173</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         CreditScore         Tenure        Balance  NumOfProducts  \\\n",
       "count  110023.000000  110023.000000  110023.000000  110023.000000   \n",
       "mean        0.613062       0.499664       0.220542       0.184440   \n",
       "std         0.160631       0.280615       0.250255       0.181571   \n",
       "min         0.000000       0.000000       0.000000       0.000000   \n",
       "25%         0.494000       0.300000       0.000000       0.000000   \n",
       "50%         0.620000       0.500000       0.000000       0.333333   \n",
       "75%         0.720000       0.700000       0.478862       0.333333   \n",
       "max         1.000000       1.000000       1.000000       1.000000   \n",
       "\n",
       "       EstimatedSalary  \n",
       "count    110023.000000  \n",
       "mean          0.561571  \n",
       "std           0.251409  \n",
       "min           0.000000  \n",
       "25%           0.372179  \n",
       "50%           0.589160  \n",
       "75%           0.773173  \n",
       "max           1.000000  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df[numeric_cols].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = OneHotEncoder(handle_unknown='ignore', sparse_output=False)\n",
    "encoder.fit(raw_df[categorical_cols])\n",
    "encoded_cols = list(encoder.get_feature_names_out(categorical_cols))\n",
    "encoded_df = pd.DataFrame(data=encoder.transform(raw_df[categorical_cols]), columns=encoded_cols)\n",
    "encoded_df.index = raw_df.index\n",
    "raw_df = pd.concat([raw_df, encoded_df], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "encoded_df = pd.DataFrame(data=encoder.transform(test_df[categorical_cols]), columns=encoded_cols)\n",
    "encoded_df.index = test_df.index\n",
    "test_df = pd.concat([test_df, encoded_df], axis=1).copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "inputs = raw_df[numeric_cols+encoded_cols]\n",
    "targets = raw_df['Exited']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_inputs, val_inputs, train_targets, val_targets = train_test_split(inputs, targets,\n",
    "                                                                        test_size=0.2,\n",
    "                                                                        random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_inputs = test_df[numeric_cols+encoded_cols]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ML Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_params(**params):\n",
    "    model = XGBClassifier(**params)\n",
    "    model.fit(train_inputs, train_targets)\n",
    "    train_acc = model.score(train_inputs, train_targets)\n",
    "    val_acc = model.score(val_inputs, val_targets)\n",
    "    return train_acc, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test None: train_acc = 0.857499, val_acc = 0.839307\n",
      "Test 0: train_acc = 0.857499, val_acc = 0.839307\n",
      "Test 42: train_acc = 0.857499, val_acc = 0.839307\n",
      "Test 1212: train_acc = 0.857499, val_acc = 0.839307\n"
     ]
    }
   ],
   "source": [
    "for i in [None, 0, 42, 1212]:\n",
    "    train_acc, val_acc = test_params(n_jobs=-1, random_state=i)\n",
    "    print(\"Test {}: train_acc = {:6f}, val_acc = {:6f}\".format(i, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 100: train_acc = 0.857499, val_acc = 0.839307\n",
      "Test 150: train_acc = 0.864603, val_acc = 0.837428\n",
      "Test 250: train_acc = 0.876752, val_acc = 0.837277\n",
      "Test 350: train_acc = 0.886455, val_acc = 0.834884\n",
      "Test 500: train_acc = 0.898142, val_acc = 0.832854\n"
     ]
    }
   ],
   "source": [
    "for i in [100,150,250,350,500]:\n",
    "    train_acc, val_acc = test_params(n_jobs=-1, random_state=42,\n",
    "                                     n_estimators=i)\n",
    "    print(\"Test {}: train_acc = {:6f}, val_acc = {:6f}\".format(i, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 3: train_acc = 0.844388, val_acc = 0.842124\n",
      "Test 4: train_acc = 0.847342, val_acc = 0.841458\n",
      "Test 5: train_acc = 0.853416, val_acc = 0.839640\n",
      "Test 6: train_acc = 0.864603, val_acc = 0.837428\n",
      "Test 9: train_acc = 0.915449, val_acc = 0.831309\n",
      "Test 12: train_acc = 0.974982, val_acc = 0.824855\n",
      "Test 15: train_acc = 0.993994, val_acc = 0.822825\n"
     ]
    }
   ],
   "source": [
    "for i in [3,4,5,6,9,12,15]:\n",
    "    train_acc, val_acc = test_params(n_jobs=-1, random_state=42,\n",
    "                                     n_estimators=150, max_depth=i)\n",
    "    print(\"Test {}: train_acc = {:6f}, val_acc = {:6f}\".format(i, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0.005: train_acc = 0.803570, val_acc = 0.804526\n",
      "Test 0.01: train_acc = 0.833875, val_acc = 0.834096\n",
      "Test 0.05: train_acc = 0.841987, val_acc = 0.842124\n",
      "Test 0.1: train_acc = 0.843835, val_acc = 0.841731\n",
      "Test 0.2: train_acc = 0.845729, val_acc = 0.841731\n",
      "Test 0.4: train_acc = 0.849228, val_acc = 0.841579\n"
     ]
    }
   ],
   "source": [
    "for i in [0.005,0.01,0.05,0.1,0.2,0.4]:\n",
    "    train_acc, val_acc = test_params(n_jobs=-1, random_state=42,\n",
    "                                     n_estimators=150, max_depth=4,\n",
    "                                     learning_rate=i)\n",
    "    print(\"Test {}: train_acc = {:6f}, val_acc = {:6f}\".format(i, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test 0.3: train_acc = 0.843827, val_acc = 0.841518\n",
      "Test 0.5: train_acc = 0.843949, val_acc = 0.842336\n",
      "Test 0.7: train_acc = 0.843865, val_acc = 0.841973\n",
      "Test 0.9: train_acc = 0.843850, val_acc = 0.841731\n",
      "Test 0.99: train_acc = 0.843524, val_acc = 0.841397\n"
     ]
    }
   ],
   "source": [
    "for i in [0.3,0.5,0.7,0.9,0.99]:\n",
    "    train_acc, val_acc = test_params(n_jobs=-1, random_state=42,\n",
    "                                     n_estimators=150, max_depth=4,\n",
    "                                     learning_rate=0.1, subsample=i)\n",
    "    print(\"Test {}: train_acc = {:6f}, val_acc = {:6f}\".format(i, train_acc, val_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_model = XGBClassifier(n_jobs=-1, random_state=42,\n",
    "                          n_estimators=150, max_depth=4,\n",
    "                          learning_rate=0.1, subsample=0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {\n",
       "  /* Definition of color scheme common for light and dark mode */\n",
       "  --sklearn-color-text: black;\n",
       "  --sklearn-color-line: gray;\n",
       "  /* Definition of color scheme for unfitted estimators */\n",
       "  --sklearn-color-unfitted-level-0: #fff5e6;\n",
       "  --sklearn-color-unfitted-level-1: #f6e4d2;\n",
       "  --sklearn-color-unfitted-level-2: #ffe0b3;\n",
       "  --sklearn-color-unfitted-level-3: chocolate;\n",
       "  /* Definition of color scheme for fitted estimators */\n",
       "  --sklearn-color-fitted-level-0: #f0f8ff;\n",
       "  --sklearn-color-fitted-level-1: #d4ebff;\n",
       "  --sklearn-color-fitted-level-2: #b3dbfd;\n",
       "  --sklearn-color-fitted-level-3: cornflowerblue;\n",
       "\n",
       "  /* Specific color for light theme */\n",
       "  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));\n",
       "  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));\n",
       "  --sklearn-color-icon: #696969;\n",
       "\n",
       "  @media (prefers-color-scheme: dark) {\n",
       "    /* Redefinition of color scheme for dark theme */\n",
       "    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));\n",
       "    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));\n",
       "    --sklearn-color-icon: #878787;\n",
       "  }\n",
       "}\n",
       "\n",
       "#sk-container-id-1 {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 pre {\n",
       "  padding: 0;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-hidden--visually {\n",
       "  border: 0;\n",
       "  clip: rect(1px 1px 1px 1px);\n",
       "  clip: rect(1px, 1px, 1px, 1px);\n",
       "  height: 1px;\n",
       "  margin: -1px;\n",
       "  overflow: hidden;\n",
       "  padding: 0;\n",
       "  position: absolute;\n",
       "  width: 1px;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-dashed-wrapped {\n",
       "  border: 1px dashed var(--sklearn-color-line);\n",
       "  margin: 0 0.4em 0.5em 0.4em;\n",
       "  box-sizing: border-box;\n",
       "  padding-bottom: 0.4em;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-container {\n",
       "  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`\n",
       "     but bootstrap.min.css set `[hidden] { display: none !important; }`\n",
       "     so we also need the `!important` here to be able to override the\n",
       "     default hidden behavior on the sphinx rendered scikit-learn.org.\n",
       "     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */\n",
       "  display: inline-block !important;\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-text-repr-fallback {\n",
       "  display: none;\n",
       "}\n",
       "\n",
       "div.sk-parallel-item,\n",
       "div.sk-serial,\n",
       "div.sk-item {\n",
       "  /* draw centered vertical line to link estimators */\n",
       "  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));\n",
       "  background-size: 2px 100%;\n",
       "  background-repeat: no-repeat;\n",
       "  background-position: center center;\n",
       "}\n",
       "\n",
       "/* Parallel-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item::after {\n",
       "  content: \"\";\n",
       "  width: 100%;\n",
       "  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);\n",
       "  flex-grow: 1;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel {\n",
       "  display: flex;\n",
       "  align-items: stretch;\n",
       "  justify-content: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  position: relative;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:first-child::after {\n",
       "  align-self: flex-end;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:last-child::after {\n",
       "  align-self: flex-start;\n",
       "  width: 50%;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-parallel-item:only-child::after {\n",
       "  width: 0;\n",
       "}\n",
       "\n",
       "/* Serial-specific style estimator block */\n",
       "\n",
       "#sk-container-id-1 div.sk-serial {\n",
       "  display: flex;\n",
       "  flex-direction: column;\n",
       "  align-items: center;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  padding-right: 1em;\n",
       "  padding-left: 1em;\n",
       "}\n",
       "\n",
       "\n",
       "/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is\n",
       "clickable and can be expanded/collapsed.\n",
       "- Pipeline and ColumnTransformer use this feature and define the default style\n",
       "- Estimators will overwrite some part of the style using the `sk-estimator` class\n",
       "*/\n",
       "\n",
       "/* Pipeline and ColumnTransformer style (default) */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable {\n",
       "  /* Default theme specific background. It is overwritten whether we have a\n",
       "  specific estimator or a Pipeline/ColumnTransformer */\n",
       "  background-color: var(--sklearn-color-background);\n",
       "}\n",
       "\n",
       "/* Toggleable label */\n",
       "#sk-container-id-1 label.sk-toggleable__label {\n",
       "  cursor: pointer;\n",
       "  display: block;\n",
       "  width: 100%;\n",
       "  margin-bottom: 0;\n",
       "  padding: 0.5em;\n",
       "  box-sizing: border-box;\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:before {\n",
       "  /* Arrow on the left of the label */\n",
       "  content: \"▸\";\n",
       "  float: left;\n",
       "  margin-right: 0.25em;\n",
       "  color: var(--sklearn-color-icon);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {\n",
       "  color: var(--sklearn-color-text);\n",
       "}\n",
       "\n",
       "/* Toggleable content - dropdown */\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content {\n",
       "  max-height: 0;\n",
       "  max-width: 0;\n",
       "  overflow: hidden;\n",
       "  text-align: left;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content pre {\n",
       "  margin: 0.2em;\n",
       "  border-radius: 0.25em;\n",
       "  color: var(--sklearn-color-text);\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-toggleable__content.fitted pre {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {\n",
       "  /* Expand drop-down */\n",
       "  max-height: 200px;\n",
       "  max-width: 100%;\n",
       "  overflow: auto;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {\n",
       "  content: \"▾\";\n",
       "}\n",
       "\n",
       "/* Pipeline/ColumnTransformer-specific style */\n",
       "\n",
       "#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator-specific style */\n",
       "\n",
       "/* Colorize estimator box */\n",
       "#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label label.sk-toggleable__label,\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  /* The background is the default theme color */\n",
       "  color: var(--sklearn-color-text-on-default-background);\n",
       "}\n",
       "\n",
       "/* On hover, darken the color of the background */\n",
       "#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "/* Label box, darken color on hover, fitted */\n",
       "#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {\n",
       "  color: var(--sklearn-color-text);\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Estimator label */\n",
       "\n",
       "#sk-container-id-1 div.sk-label label {\n",
       "  font-family: monospace;\n",
       "  font-weight: bold;\n",
       "  display: inline-block;\n",
       "  line-height: 1.2em;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-label-container {\n",
       "  text-align: center;\n",
       "}\n",
       "\n",
       "/* Estimator-specific */\n",
       "#sk-container-id-1 div.sk-estimator {\n",
       "  font-family: monospace;\n",
       "  border: 1px dotted var(--sklearn-color-border-box);\n",
       "  border-radius: 0.25em;\n",
       "  box-sizing: border-box;\n",
       "  margin-bottom: 0.5em;\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-0);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-0);\n",
       "}\n",
       "\n",
       "/* on hover */\n",
       "#sk-container-id-1 div.sk-estimator:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-2);\n",
       "}\n",
       "\n",
       "#sk-container-id-1 div.sk-estimator.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-2);\n",
       "}\n",
       "\n",
       "/* Specification for estimator info (e.g. \"i\" and \"?\") */\n",
       "\n",
       "/* Common style for \"i\" and \"?\" */\n",
       "\n",
       ".sk-estimator-doc-link,\n",
       "a:link.sk-estimator-doc-link,\n",
       "a:visited.sk-estimator-doc-link {\n",
       "  float: right;\n",
       "  font-size: smaller;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1em;\n",
       "  height: 1em;\n",
       "  width: 1em;\n",
       "  text-decoration: none !important;\n",
       "  margin-left: 1ex;\n",
       "  /* unfitted */\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted,\n",
       "a:link.sk-estimator-doc-link.fitted,\n",
       "a:visited.sk-estimator-doc-link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "div.sk-estimator:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link:hover,\n",
       ".sk-estimator-doc-link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover,\n",
       "div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,\n",
       ".sk-estimator-doc-link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "/* Span, style for the box shown on hovering the info icon */\n",
       ".sk-estimator-doc-link span {\n",
       "  display: none;\n",
       "  z-index: 9999;\n",
       "  position: relative;\n",
       "  font-weight: normal;\n",
       "  right: .2ex;\n",
       "  padding: .5ex;\n",
       "  margin: .5ex;\n",
       "  width: min-content;\n",
       "  min-width: 20ex;\n",
       "  max-width: 50ex;\n",
       "  color: var(--sklearn-color-text);\n",
       "  box-shadow: 2pt 2pt 4pt #999;\n",
       "  /* unfitted */\n",
       "  background: var(--sklearn-color-unfitted-level-0);\n",
       "  border: .5pt solid var(--sklearn-color-unfitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link.fitted span {\n",
       "  /* fitted */\n",
       "  background: var(--sklearn-color-fitted-level-0);\n",
       "  border: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "\n",
       ".sk-estimator-doc-link:hover span {\n",
       "  display: block;\n",
       "}\n",
       "\n",
       "/* \"?\"-specific style due to the `<a>` HTML tag */\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link {\n",
       "  float: right;\n",
       "  font-size: 1rem;\n",
       "  line-height: 1em;\n",
       "  font-family: monospace;\n",
       "  background-color: var(--sklearn-color-background);\n",
       "  border-radius: 1rem;\n",
       "  height: 1rem;\n",
       "  width: 1rem;\n",
       "  text-decoration: none;\n",
       "  /* unfitted */\n",
       "  color: var(--sklearn-color-unfitted-level-1);\n",
       "  border: var(--sklearn-color-unfitted-level-1) 1pt solid;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted {\n",
       "  /* fitted */\n",
       "  border: var(--sklearn-color-fitted-level-1) 1pt solid;\n",
       "  color: var(--sklearn-color-fitted-level-1);\n",
       "}\n",
       "\n",
       "/* On hover */\n",
       "#sk-container-id-1 a.estimator_doc_link:hover {\n",
       "  /* unfitted */\n",
       "  background-color: var(--sklearn-color-unfitted-level-3);\n",
       "  color: var(--sklearn-color-background);\n",
       "  text-decoration: none;\n",
       "}\n",
       "\n",
       "#sk-container-id-1 a.estimator_doc_link.fitted:hover {\n",
       "  /* fitted */\n",
       "  background-color: var(--sklearn-color-fitted-level-3);\n",
       "}\n",
       "</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=150, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator fitted sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label fitted sk-toggleable__label-arrow fitted\">&nbsp;XGBClassifier<span class=\"sk-estimator-doc-link fitted\">i<span>Fitted</span></span></label><div class=\"sk-toggleable__content fitted\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=150, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=42, ...)</pre></div> </div></div></div></div>"
      ],
      "text/plain": [
       "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
       "              colsample_bylevel=None, colsample_bynode=None,\n",
       "              colsample_bytree=None, device=None, early_stopping_rounds=None,\n",
       "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
       "              gamma=None, grow_policy=None, importance_type=None,\n",
       "              interaction_constraints=None, learning_rate=0.1, max_bin=None,\n",
       "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
       "              max_delta_step=None, max_depth=4, max_leaves=None,\n",
       "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
       "              multi_strategy=None, n_estimators=150, n_jobs=-1,\n",
       "              num_parallel_tree=None, random_state=42, ...)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.fit(train_inputs, train_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8419729148362468"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_model.score(val_inputs, val_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb_model.predict(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds = xgb_model.predict_proba(test_inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.02008939, 0.6231572 , 0.09258449, ..., 0.04302597, 0.40937373,\n",
       "       0.28447258], dtype=float32)"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(110023, 110023)"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_inputs), len(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['Exited'] = preds[:,1]\n",
    "sub_df.to_csv('bank-churn-data/sub2.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "from lightgbm import LGBMClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test_params(**params):\n",
    "    model = LGBMClassifier(**params)\n",
    "    model.fit(train_inputs, train_targets)\n",
    "    train_acc = model.score(train_inputs, train_targets)\n",
    "    val_acc = model.score(val_inputs, val_targets)\n",
    "    return train_acc, val_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.8457209510175949, 0.8417608386099918)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_params()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feed Forward NN Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((165034, 17), (165034,))"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs.shape, targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_tensors = torch.tensor(inputs.values, dtype=torch.float32)\n",
    "target_tensors = torch.tensor(targets.values, dtype=torch.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([165034, 17]), torch.Size([165034]))"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensors.shape, target_tensors.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([0.6360, 0.3000, 0.0000, 0.3333, 0.9073, 0.0000, 0.0000, 1.0000, 1.0000,\n",
       "         0.0000, 0.0000, 0.0000, 1.0000, 0.0000, 1.0000, 1.0000, 0.0000]),\n",
       " tensor(0.))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_ds = TensorDataset(input_tensors, target_tensors)\n",
    "raw_ds[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x2bb00920c30>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random_seed = 42\n",
    "torch.manual_seed(random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "val_size = int(len(raw_ds)*0.2)\n",
    "train_size = len(raw_ds)-val_size\n",
    "from torch.utils.data import random_split\n",
    "train_ds, val_ds = random_split(raw_ds, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dl = DataLoader(raw_ds, batch_size, shuffle=True)\n",
    "val_dl = DataLoader(raw_ds, batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaseModel(nn.Module):\n",
    "    def training_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        probs = torch.sigmoid(outputs[:,0])\n",
    "        loss = F.binary_cross_entropy(probs, targets)\n",
    "        return loss\n",
    "\n",
    "    def validation_step(self, batch):\n",
    "        inputs, targets = batch\n",
    "        outputs = self(inputs)\n",
    "        probs = torch.sigmoid(outputs[:,0])\n",
    "        loss = F.binary_cross_entropy(probs, targets)\n",
    "        preds = (probs > 0.5).int()\n",
    "        acc = accuracy_score(targets, preds)\n",
    "        return {'val_loss': loss.item(), 'val_acc': acc}\n",
    "\n",
    "    def validation_epoch_end(self, outputs):\n",
    "        batch_losses = [x['val_loss'] for x in outputs]\n",
    "        epoch_loss = np.mean(batch_losses)\n",
    "        batch_accs = [x['val_acc'] for x in outputs]\n",
    "        epoch_acc = np.mean(batch_accs)\n",
    "        return {'val_loss': epoch_loss, 'val_acc': epoch_acc}\n",
    "\n",
    "    def epoch_end(self, epoch, result):\n",
    "        print('Epoch {}, val_loss: {:4f}, val_acc: {:4f}'.format(epoch,\n",
    "                                                                 result['val_loss'],\n",
    "                                                                 result['val_acc']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFWith4LayerModel(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(17, 64)\n",
    "        self.linear2 = nn.Linear(64,32)\n",
    "        self.linear3 = nn.Linear(32,1)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        out = self.linear1(xb)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_with4_model = FFWith4LayerModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, val_dl):\n",
    "    outputs = [model.validation_step(batch) for batch in val_dl]\n",
    "    return model.validation_epoch_end(outputs)\n",
    "\n",
    "def fit(epochs, lr, model, train_dl, val_dl, opt_func=torch.optim.SGD):\n",
    "    history = []\n",
    "    opt = opt_func(model.parameters(), lr)\n",
    "    for epoch in range(epochs):\n",
    "        for batch in train_dl:\n",
    "            loss = model.training_step(batch)\n",
    "            loss.backward()\n",
    "            opt.step()\n",
    "            opt.zero_grad()\n",
    "        result = evaluate(model, val_dl)\n",
    "        model.epoch_end(epoch, result)\n",
    "        history.append(result)\n",
    "    return history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.74759558818137, 'val_acc': 0.21157439865481076}]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = [evaluate(ff_with4_model, val_dl)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val_loss: 0.417004, val_acc: 0.813347\n",
      "Epoch 1, val_loss: 0.372343, val_acc: 0.836612\n",
      "Epoch 2, val_loss: 0.372295, val_acc: 0.835043\n",
      "Epoch 3, val_loss: 0.364732, val_acc: 0.839259\n"
     ]
    }
   ],
   "source": [
    "history += fit(4, 0.2, ff_with4_model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val_loss: 0.364592, val_acc: 0.839183\n",
      "Epoch 1, val_loss: 0.365489, val_acc: 0.836885\n",
      "Epoch 2, val_loss: 0.362969, val_acc: 0.840512\n",
      "Epoch 3, val_loss: 0.363777, val_acc: 0.838998\n"
     ]
    }
   ],
   "source": [
    "history += fit(4, 0.1, ff_with4_model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val_loss: 0.362209, val_acc: 0.840106\n",
      "Epoch 1, val_loss: 0.362078, val_acc: 0.840533\n",
      "Epoch 2, val_loss: 0.362181, val_acc: 0.840539\n",
      "Epoch 3, val_loss: 0.362156, val_acc: 0.840745\n"
     ]
    }
   ],
   "source": [
    "history += fit(4, 0.05, ff_with4_model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_ds = TensorDataset(torch.tensor(test_inputs.values, dtype=torch.float32))\n",
    "test_dl = DataLoader(test_ds, batch_size*2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(test_dl, model):\n",
    "    all_preds = []\n",
    "    for batch in test_dl:\n",
    "        inputs, = batch\n",
    "        outputs = model(inputs)\n",
    "        probs = torch.sigmoid(outputs[:,0])\n",
    "        all_preds += list(probs.detach().numpy())\n",
    "    return all_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.021964546,\n",
       " 0.6661228,\n",
       " 0.07467656,\n",
       " 0.43269598,\n",
       " 0.5157162,\n",
       " 0.04084793,\n",
       " 0.017103769,\n",
       " 0.029056933,\n",
       " 0.3144927,\n",
       " 0.015317729,\n",
       " 0.24044013,\n",
       " 0.038533427,\n",
       " 0.013477389,\n",
       " 0.3417657,\n",
       " 0.58137757,\n",
       " 0.024719004,\n",
       " 0.092116594,\n",
       " 0.70870906,\n",
       " 0.035172928,\n",
       " 0.19546402,\n",
       " 0.044325173,\n",
       " 0.2111648,\n",
       " 0.45060343,\n",
       " 0.019957386,\n",
       " 0.7513113,\n",
       " 0.27792042,\n",
       " 0.70135796,\n",
       " 0.3035775,\n",
       " 0.1845761,\n",
       " 0.34595495,\n",
       " 0.04633685,\n",
       " 0.045434188,\n",
       " 0.22857207,\n",
       " 0.28670517,\n",
       " 0.08235702,\n",
       " 0.02466992,\n",
       " 0.6359342,\n",
       " 0.09009592,\n",
       " 0.21631628,\n",
       " 0.74663675,\n",
       " 0.66049707,\n",
       " 0.2737705,\n",
       " 0.127582,\n",
       " 0.014770898,\n",
       " 0.6571522,\n",
       " 0.11067122,\n",
       " 0.026267536,\n",
       " 0.025350684,\n",
       " 0.007871462,\n",
       " 0.55401385,\n",
       " 0.12791197,\n",
       " 0.0138231255,\n",
       " 0.015368891,\n",
       " 0.44477633,\n",
       " 0.04452595,\n",
       " 0.37381294,\n",
       " 0.22222887,\n",
       " 0.014047094,\n",
       " 0.029176062,\n",
       " 0.3778199,\n",
       " 0.015519303,\n",
       " 0.034504123,\n",
       " 0.24961875,\n",
       " 0.3611247,\n",
       " 0.014472051,\n",
       " 0.02916497,\n",
       " 0.5773946,\n",
       " 0.049026307,\n",
       " 0.15988624,\n",
       " 0.041737154,\n",
       " 0.482514,\n",
       " 0.5301539,\n",
       " 0.5060219,\n",
       " 0.049410943,\n",
       " 0.02825597,\n",
       " 0.7078681,\n",
       " 0.19476993,\n",
       " 0.08629817,\n",
       " 0.095966995,\n",
       " 0.04297341,\n",
       " 0.031843316,\n",
       " 0.03997492,\n",
       " 0.56734085,\n",
       " 0.07240021,\n",
       " 0.4856029,\n",
       " 0.0853359,\n",
       " 0.2171402,\n",
       " 0.083029665,\n",
       " 0.22047777,\n",
       " 0.09168149,\n",
       " 0.40834227,\n",
       " 0.09147454,\n",
       " 0.084030665,\n",
       " 0.017630022,\n",
       " 0.014937323,\n",
       " 0.014640855,\n",
       " 0.9732011,\n",
       " 0.03351901,\n",
       " 0.48572204,\n",
       " 0.20312427,\n",
       " 0.028623175,\n",
       " 0.09633084,\n",
       " 0.007885626,\n",
       " 0.67703366,\n",
       " 0.42202127,\n",
       " 0.7183631,\n",
       " 0.057905734,\n",
       " 0.076521195,\n",
       " 0.019041998,\n",
       " 0.21476126,\n",
       " 0.41946122,\n",
       " 0.4265182,\n",
       " 0.37274265,\n",
       " 0.058724955,\n",
       " 0.097521044,\n",
       " 0.028632093,\n",
       " 0.013991898,\n",
       " 0.18854114,\n",
       " 0.32865122,\n",
       " 0.054231297,\n",
       " 0.05439163,\n",
       " 0.024024265,\n",
       " 0.014678771,\n",
       " 0.028069349,\n",
       " 0.24273318,\n",
       " 0.18649985,\n",
       " 0.045272596,\n",
       " 0.032719344,\n",
       " 0.7409347,\n",
       " 0.027138881,\n",
       " 0.029493546,\n",
       " 0.32605717,\n",
       " 0.7189333,\n",
       " 0.06330985,\n",
       " 0.06107496,\n",
       " 0.15133281,\n",
       " 0.15969466,\n",
       " 0.015372283,\n",
       " 0.37728044,\n",
       " 0.25511882,\n",
       " 0.024447642,\n",
       " 0.11934879,\n",
       " 0.03845249,\n",
       " 0.016921528,\n",
       " 0.20752515,\n",
       " 0.70049864,\n",
       " 0.066651635,\n",
       " 0.54896486,\n",
       " 0.3947327,\n",
       " 0.03320395,\n",
       " 0.055750992,\n",
       " 0.04447048,\n",
       " 0.027044574,\n",
       " 0.89259946,\n",
       " 0.69754887,\n",
       " 0.031144707,\n",
       " 0.019438788,\n",
       " 0.26134506,\n",
       " 0.22151078,\n",
       " 0.039073646,\n",
       " 0.14921579,\n",
       " 0.060709067,\n",
       " 0.37468195,\n",
       " 0.7292901,\n",
       " 0.4221475,\n",
       " 0.084341615,\n",
       " 0.7020858,\n",
       " 0.68895835,\n",
       " 0.67766035,\n",
       " 0.38411248,\n",
       " 0.6261084,\n",
       " 0.03726299,\n",
       " 0.367001,\n",
       " 0.09612537,\n",
       " 0.039545733,\n",
       " 0.27333695,\n",
       " 0.052525505,\n",
       " 0.5118794,\n",
       " 0.07360788,\n",
       " 0.014929319,\n",
       " 0.6085588,\n",
       " 0.45468277,\n",
       " 0.05807473,\n",
       " 0.015295355,\n",
       " 0.015882822,\n",
       " 0.70551074,\n",
       " 0.43140534,\n",
       " 0.06220762,\n",
       " 0.28622535,\n",
       " 0.22833847,\n",
       " 0.04983406,\n",
       " 0.6018413,\n",
       " 0.4875369,\n",
       " 0.20290098,\n",
       " 0.35144746,\n",
       " 0.047978334,\n",
       " 0.8729574,\n",
       " 0.017153187,\n",
       " 0.00782445,\n",
       " 0.07729657,\n",
       " 0.1646134,\n",
       " 0.028133698,\n",
       " 0.5570959,\n",
       " 0.01349481,\n",
       " 0.24781242,\n",
       " 0.028131925,\n",
       " 0.014442225,\n",
       " 0.015930062,\n",
       " 0.39088872,\n",
       " 0.0652916,\n",
       " 0.6222343,\n",
       " 0.018067243,\n",
       " 0.1487361,\n",
       " 0.025410121,\n",
       " 0.042301066,\n",
       " 0.361153,\n",
       " 0.034945868,\n",
       " 0.014719593,\n",
       " 0.5606772,\n",
       " 0.16617379,\n",
       " 0.046130177,\n",
       " 0.21205974,\n",
       " 0.35256007,\n",
       " 0.09269961,\n",
       " 0.59018576,\n",
       " 0.67186916,\n",
       " 0.4513227,\n",
       " 0.5730784,\n",
       " 0.19159718,\n",
       " 0.014146434,\n",
       " 0.047540672,\n",
       " 0.020918556,\n",
       " 0.008916852,\n",
       " 0.352134,\n",
       " 0.2797427,\n",
       " 0.37493828,\n",
       " 0.48933968,\n",
       " 0.08466978,\n",
       " 0.9132429,\n",
       " 0.05166513,\n",
       " 0.11759133,\n",
       " 0.20815694,\n",
       " 0.16800046,\n",
       " 0.7098657,\n",
       " 0.64220357,\n",
       " 0.14050907,\n",
       " 0.052899744,\n",
       " 0.029515322,\n",
       " 0.097378224,\n",
       " 0.014382154,\n",
       " 0.48120257,\n",
       " 0.13781121,\n",
       " 0.08228485,\n",
       " 0.037226662,\n",
       " 0.028954428,\n",
       " 0.044635158,\n",
       " 0.018390182,\n",
       " 0.023554211,\n",
       " 0.13260344,\n",
       " 0.7331606,\n",
       " 0.016335078,\n",
       " 0.40465608,\n",
       " 0.08153268,\n",
       " 0.080771714,\n",
       " 0.023803463,\n",
       " 0.013566871,\n",
       " 0.69294953,\n",
       " 0.10765774,\n",
       " 0.65508896,\n",
       " 0.07440287,\n",
       " 0.008449006,\n",
       " 0.013615417,\n",
       " 0.047496643,\n",
       " 0.25605643,\n",
       " 0.04157036,\n",
       " 0.44814435,\n",
       " 0.25359717,\n",
       " 0.13087752,\n",
       " 0.4653427,\n",
       " 0.059897736,\n",
       " 0.06477095,\n",
       " 0.08098603,\n",
       " 0.24009697,\n",
       " 0.008404215,\n",
       " 0.46946713,\n",
       " 0.29158467,\n",
       " 0.0498255,\n",
       " 0.1388817,\n",
       " 0.04932803,\n",
       " 0.035341796,\n",
       " 0.027857404,\n",
       " 0.40727267,\n",
       " 0.5810448,\n",
       " 0.28741145,\n",
       " 0.0371565,\n",
       " 0.036569603,\n",
       " 0.20386128,\n",
       " 0.027303299,\n",
       " 0.70766175,\n",
       " 0.031184165,\n",
       " 0.014605428,\n",
       " 0.039888233,\n",
       " 0.083612934,\n",
       " 0.2703847,\n",
       " 0.5097425,\n",
       " 0.34292248,\n",
       " 0.08932135,\n",
       " 0.013705171,\n",
       " 0.046105634,\n",
       " 0.008379676,\n",
       " 0.09484626,\n",
       " 0.08415935,\n",
       " 0.73246175,\n",
       " 0.4439069,\n",
       " 0.084857985,\n",
       " 0.08524493,\n",
       " 0.013651415,\n",
       " 0.24898496,\n",
       " 0.048503242,\n",
       " 0.015556291,\n",
       " 0.16317031,\n",
       " 0.06322193,\n",
       " 0.031622387,\n",
       " 0.07938718,\n",
       " 0.13533008,\n",
       " 0.027664209,\n",
       " 0.7583225,\n",
       " 0.0848414,\n",
       " 0.3242363,\n",
       " 0.18440202,\n",
       " 0.031295657,\n",
       " 0.8989371,\n",
       " 0.013511249,\n",
       " 0.11221608,\n",
       " 0.13431482,\n",
       " 0.7335535,\n",
       " 0.047813095,\n",
       " 0.0090797935,\n",
       " 0.16642371,\n",
       " 0.0400771,\n",
       " 0.49472883,\n",
       " 0.030802038,\n",
       " 0.038397398,\n",
       " 0.008167586,\n",
       " 0.34788477,\n",
       " 0.061303042,\n",
       " 0.34131297,\n",
       " 0.029394316,\n",
       " 0.014826933,\n",
       " 0.02313654,\n",
       " 0.07120538,\n",
       " 0.35430965,\n",
       " 0.29851815,\n",
       " 0.026171995,\n",
       " 0.49994367,\n",
       " 0.11008556,\n",
       " 0.3668045,\n",
       " 0.013925152,\n",
       " 0.07957979,\n",
       " 0.113528065,\n",
       " 0.23052599,\n",
       " 0.012829752,\n",
       " 0.073107526,\n",
       " 0.032667138,\n",
       " 0.622061,\n",
       " 0.08061754,\n",
       " 0.088691734,\n",
       " 0.19094916,\n",
       " 0.16241303,\n",
       " 0.0278239,\n",
       " 0.09440198,\n",
       " 0.50345135,\n",
       " 0.06769497,\n",
       " 0.12346612,\n",
       " 0.0952328,\n",
       " 0.016430782,\n",
       " 0.014315295,\n",
       " 0.016094355,\n",
       " 0.055516265,\n",
       " 0.014475499,\n",
       " 0.026726691,\n",
       " 0.07472791,\n",
       " 0.73546875,\n",
       " 0.013516702,\n",
       " 0.028572435,\n",
       " 0.68691456,\n",
       " 0.073896885,\n",
       " 0.14287321,\n",
       " 0.02565801,\n",
       " 0.029478056,\n",
       " 0.028936924,\n",
       " 0.68605924,\n",
       " 0.091836125,\n",
       " 0.097622775,\n",
       " 0.5520889,\n",
       " 0.42779884,\n",
       " 0.09219133,\n",
       " 0.074563175,\n",
       " 0.085198,\n",
       " 0.74751157,\n",
       " 0.67031974,\n",
       " 0.41841805,\n",
       " 0.30848208,\n",
       " 0.014536502,\n",
       " 0.013290736,\n",
       " 0.07931965,\n",
       " 0.7481745,\n",
       " 0.54629785,\n",
       " 0.039417237,\n",
       " 0.016402416,\n",
       " 0.0961361,\n",
       " 0.10305911,\n",
       " 0.1195393,\n",
       " 0.014043686,\n",
       " 0.08252442,\n",
       " 0.013580201,\n",
       " 0.04317702,\n",
       " 0.023227705,\n",
       " 0.51373285,\n",
       " 0.074309364,\n",
       " 0.30291626,\n",
       " 0.077745855,\n",
       " 0.4963294,\n",
       " 0.7192359,\n",
       " 0.03046258,\n",
       " 0.029344473,\n",
       " 0.03500879,\n",
       " 0.046209555,\n",
       " 0.08388638,\n",
       " 0.10776685,\n",
       " 0.15139036,\n",
       " 0.81880337,\n",
       " 0.024043415,\n",
       " 0.16435756,\n",
       " 0.25832275,\n",
       " 0.14727966,\n",
       " 0.14014438,\n",
       " 0.34815907,\n",
       " 0.015827414,\n",
       " 0.08483482,\n",
       " 0.4425873,\n",
       " 0.10860732,\n",
       " 0.19793624,\n",
       " 0.21814807,\n",
       " 0.14877787,\n",
       " 0.44517544,\n",
       " 0.08492374,\n",
       " 0.7005413,\n",
       " 0.026836958,\n",
       " 0.14880542,\n",
       " 0.037627075,\n",
       " 0.46707004,\n",
       " 0.21646103,\n",
       " 0.09601357,\n",
       " 0.076396614,\n",
       " 0.03950495,\n",
       " 0.06211576,\n",
       " 0.090934545,\n",
       " 0.16956933,\n",
       " 0.1956433,\n",
       " 0.018752053,\n",
       " 0.17701505,\n",
       " 0.11956209,\n",
       " 0.19929004,\n",
       " 0.121952444,\n",
       " 0.022421146,\n",
       " 0.014826878,\n",
       " 0.1501131,\n",
       " 0.01423688,\n",
       " 0.014642058,\n",
       " 0.7014933,\n",
       " 0.5361975,\n",
       " 0.029131578,\n",
       " 0.3244643,\n",
       " 0.13772908,\n",
       " 0.46019998,\n",
       " 0.6877082,\n",
       " 0.08932649,\n",
       " 0.07721187,\n",
       " 0.092224695,\n",
       " 0.46547335,\n",
       " 0.013641352,\n",
       " 0.077473685,\n",
       " 0.14988379,\n",
       " 0.028583635,\n",
       " 0.34025806,\n",
       " 0.15239914,\n",
       " 0.03902917,\n",
       " 0.024326513,\n",
       " 0.14959648,\n",
       " 0.054556917,\n",
       " 0.22574654,\n",
       " 0.41729385,\n",
       " 0.55089694,\n",
       " 0.021814907,\n",
       " 0.084309466,\n",
       " 0.24713168,\n",
       " 0.073440984,\n",
       " 0.15523265,\n",
       " 0.039772764,\n",
       " 0.25518224,\n",
       " 0.050382692,\n",
       " 0.027989686,\n",
       " 0.04614642,\n",
       " 0.33315015,\n",
       " 0.10268075,\n",
       " 0.036205087,\n",
       " 0.37649998,\n",
       " 0.023737703,\n",
       " 0.049447656,\n",
       " 0.014977086,\n",
       " 0.07739402,\n",
       " 0.09400804,\n",
       " 0.03941125,\n",
       " 0.029500246,\n",
       " 0.10007579,\n",
       " 0.2669022,\n",
       " 0.0084874015,\n",
       " 0.039726287,\n",
       " 0.6906786,\n",
       " 0.028930634,\n",
       " 0.15323825,\n",
       " 0.15983617,\n",
       " 0.0271493,\n",
       " 0.028893923,\n",
       " 0.0085063875,\n",
       " 0.19439836,\n",
       " 0.37406367,\n",
       " 0.39718688,\n",
       " 0.209103,\n",
       " 0.40559262,\n",
       " 0.13385297,\n",
       " 0.11285199,\n",
       " 0.35876134,\n",
       " 0.08856475,\n",
       " 0.24062826,\n",
       " 0.053504203,\n",
       " 0.014652855,\n",
       " 0.6650445,\n",
       " 0.07794198,\n",
       " 0.07355385,\n",
       " 0.4076873,\n",
       " 0.008622788,\n",
       " 0.04059378,\n",
       " 0.6515927,\n",
       " 0.2614728,\n",
       " 0.022895077,\n",
       " 0.23003255,\n",
       " 0.7532398,\n",
       " 0.19520414,\n",
       " 0.020696241,\n",
       " 0.7601195,\n",
       " 0.3908842,\n",
       " 0.014114854,\n",
       " 0.22285807,\n",
       " 0.19255143,\n",
       " 0.2876752,\n",
       " 0.5016463,\n",
       " 0.014369059,\n",
       " 0.0079901945,\n",
       " 0.09236304,\n",
       " 0.056206428,\n",
       " 0.013802905,\n",
       " 0.02800647,\n",
       " 0.14278305,\n",
       " 0.3497374,\n",
       " 0.008999588,\n",
       " 0.015033037,\n",
       " 0.01439331,\n",
       " 0.40769735,\n",
       " 0.015531395,\n",
       " 0.09067594,\n",
       " 0.04172532,\n",
       " 0.7742827,\n",
       " 0.35778826,\n",
       " 0.47577468,\n",
       " 0.24314152,\n",
       " 0.07605612,\n",
       " 0.016205586,\n",
       " 0.21304739,\n",
       " 0.16652916,\n",
       " 0.5689177,\n",
       " 0.07725532,\n",
       " 0.12901586,\n",
       " 0.2526688,\n",
       " 0.5316591,\n",
       " 0.07810666,\n",
       " 0.014508719,\n",
       " 0.01500984,\n",
       " 0.013865148,\n",
       " 0.01634219,\n",
       " 0.1576106,\n",
       " 0.049147323,\n",
       " 0.16831928,\n",
       " 0.015693901,\n",
       " 0.3563565,\n",
       " 0.13666329,\n",
       " 0.026151646,\n",
       " 0.0927256,\n",
       " 0.0730015,\n",
       " 0.007849692,\n",
       " 0.21862292,\n",
       " 0.064813614,\n",
       " 0.04077997,\n",
       " 0.08112401,\n",
       " 0.08444015,\n",
       " 0.48109478,\n",
       " 0.028557152,\n",
       " 0.058487922,\n",
       " 0.1627264,\n",
       " 0.008254288,\n",
       " 0.16818881,\n",
       " 0.008130809,\n",
       " 0.014233802,\n",
       " 0.4279043,\n",
       " 0.013530902,\n",
       " 0.43619892,\n",
       " 0.052887168,\n",
       " 0.14354235,\n",
       " 0.19080089,\n",
       " 0.02892762,\n",
       " 0.059708484,\n",
       " 0.40305668,\n",
       " 0.75655454,\n",
       " 0.25003818,\n",
       " 0.69667834,\n",
       " 0.16272324,\n",
       " 0.65871084,\n",
       " 0.58006686,\n",
       " 0.06870163,\n",
       " 0.06113989,\n",
       " 0.034126643,\n",
       " 0.1659346,\n",
       " 0.06769742,\n",
       " 0.03615435,\n",
       " 0.38818896,\n",
       " 0.008667099,\n",
       " 0.01804488,\n",
       " 0.17223437,\n",
       " 0.67759234,\n",
       " 0.6425097,\n",
       " 0.15203513,\n",
       " 0.59119475,\n",
       " 0.028934894,\n",
       " 0.4176677,\n",
       " 0.016105443,\n",
       " 0.043408588,\n",
       " 0.2744417,\n",
       " 0.014135712,\n",
       " 0.09521195,\n",
       " 0.23923703,\n",
       " 0.12855314,\n",
       " 0.02816616,\n",
       " 0.20081608,\n",
       " 0.5759703,\n",
       " 0.01422726,\n",
       " 0.09678248,\n",
       " 0.008040426,\n",
       " 0.19501548,\n",
       " 0.014118703,\n",
       " 0.033916365,\n",
       " 0.015263479,\n",
       " 0.2745357,\n",
       " 0.016655767,\n",
       " 0.11370829,\n",
       " 0.20112403,\n",
       " 0.21204586,\n",
       " 0.67526305,\n",
       " 0.20792018,\n",
       " 0.36458445,\n",
       " 0.00839377,\n",
       " 0.0269888,\n",
       " 0.35069254,\n",
       " 0.014367223,\n",
       " 0.16668509,\n",
       " 0.09665609,\n",
       " 0.038764108,\n",
       " 0.014547277,\n",
       " 0.015228793,\n",
       " 0.08876084,\n",
       " 0.64965373,\n",
       " 0.0120200515,\n",
       " 0.7149057,\n",
       " 0.65376043,\n",
       " 0.081099704,\n",
       " 0.014828771,\n",
       " 0.08197422,\n",
       " 0.2496452,\n",
       " 0.27373117,\n",
       " 0.026061617,\n",
       " 0.8777032,\n",
       " 0.021502472,\n",
       " 0.32231206,\n",
       " 0.1353939,\n",
       " 0.028611425,\n",
       " 0.27591366,\n",
       " 0.07029464,\n",
       " 0.19457282,\n",
       " 0.34711343,\n",
       " 0.0843692,\n",
       " 0.1720775,\n",
       " 0.01400659,\n",
       " 0.34876046,\n",
       " 0.6502793,\n",
       " 0.02231885,\n",
       " 0.27309877,\n",
       " 0.5925391,\n",
       " 0.06237763,\n",
       " 0.13743247,\n",
       " 0.2199835,\n",
       " 0.03044148,\n",
       " 0.08162042,\n",
       " 0.41971204,\n",
       " 0.014040306,\n",
       " 0.664275,\n",
       " 0.44803396,\n",
       " 0.07630594,\n",
       " 0.25428477,\n",
       " 0.07468336,\n",
       " 0.42295203,\n",
       " 0.25003737,\n",
       " 0.08868547,\n",
       " 0.25979638,\n",
       " 0.12115289,\n",
       " 0.14524426,\n",
       " 0.12389838,\n",
       " 0.11723264,\n",
       " 0.6450206,\n",
       " 0.66257155,\n",
       " 0.42008743,\n",
       " 0.08882924,\n",
       " 0.6795772,\n",
       " 0.08784113,\n",
       " 0.1159237,\n",
       " 0.6099604,\n",
       " 0.17841914,\n",
       " 0.17179005,\n",
       " 0.1490541,\n",
       " 0.1558677,\n",
       " 0.022424944,\n",
       " 0.019566983,\n",
       " 0.034267932,\n",
       " 0.253722,\n",
       " 0.15430318,\n",
       " 0.15247892,\n",
       " 0.043262538,\n",
       " 0.2779178,\n",
       " 0.16872062,\n",
       " 0.045510467,\n",
       " 0.7289149,\n",
       " 0.66113216,\n",
       " 0.051994115,\n",
       " 0.13567758,\n",
       " 0.01372192,\n",
       " 0.042241946,\n",
       " 0.35078365,\n",
       " 0.6443108,\n",
       " 0.048419546,\n",
       " 0.07574085,\n",
       " 0.08550373,\n",
       " 0.041503567,\n",
       " 0.37124598,\n",
       " 0.030253034,\n",
       " 0.0147843035,\n",
       " 0.07768309,\n",
       " 0.1999914,\n",
       " 0.09288295,\n",
       " 0.26074764,\n",
       " 0.013683434,\n",
       " 0.109718695,\n",
       " 0.088554375,\n",
       " 0.68524843,\n",
       " 0.007908414,\n",
       " 0.01375476,\n",
       " 0.42775196,\n",
       " 0.19196327,\n",
       " 0.05976195,\n",
       " 0.07378017,\n",
       " 0.6472171,\n",
       " 0.3389671,\n",
       " 0.032864016,\n",
       " 0.013980496,\n",
       " 0.015489208,\n",
       " 0.01610067,\n",
       " 0.3813439,\n",
       " 0.7548132,\n",
       " 0.11332988,\n",
       " 0.21651557,\n",
       " 0.12303771,\n",
       " 0.027005415,\n",
       " 0.2185472,\n",
       " 0.33623967,\n",
       " 0.030191332,\n",
       " 0.52236146,\n",
       " 0.008065988,\n",
       " 0.7116034,\n",
       " 0.48449856,\n",
       " 0.20076136,\n",
       " 0.03541526,\n",
       " 0.032124225,\n",
       " 0.16839987,\n",
       " 0.21750325,\n",
       " 0.017811729,\n",
       " 0.10179762,\n",
       " 0.020172944,\n",
       " 0.30562955,\n",
       " 0.03981045,\n",
       " 0.044532638,\n",
       " 0.04531664,\n",
       " 0.11526275,\n",
       " 0.044120237,\n",
       " 0.18778016,\n",
       " 0.027839778,\n",
       " 0.00764667,\n",
       " 0.027386256,\n",
       " 0.6590338,\n",
       " 0.10749996,\n",
       " 0.13481936,\n",
       " 0.682648,\n",
       " 0.015067235,\n",
       " 0.12761252,\n",
       " 0.027594052,\n",
       " 0.026485968,\n",
       " 0.3556418,\n",
       " 0.07776895,\n",
       " 0.008159412,\n",
       " 0.013796862,\n",
       " 0.09009119,\n",
       " 0.008054277,\n",
       " 0.01381193,\n",
       " 0.0862469,\n",
       " 0.12359421,\n",
       " 0.074415445,\n",
       " 0.5622953,\n",
       " 0.044851456,\n",
       " 0.04015593,\n",
       " 0.86081845,\n",
       " 0.35914698,\n",
       " 0.45839584,\n",
       " 0.028245201,\n",
       " 0.03365822,\n",
       " 0.8351707,\n",
       " 0.23380184,\n",
       " 0.16590957,\n",
       " 0.10632791,\n",
       " 0.0289647,\n",
       " 0.19833972,\n",
       " 0.6921541,\n",
       " 0.64689595,\n",
       " 0.014236452,\n",
       " 0.6012398,\n",
       " 0.2415336,\n",
       " 0.008468114,\n",
       " 0.5079344,\n",
       " 0.70807076,\n",
       " 0.025318341,\n",
       " 0.3193737,\n",
       " 0.0976445,\n",
       " 0.026709331,\n",
       " 0.7028623,\n",
       " 0.024984056,\n",
       " 0.045617726,\n",
       " 0.4531745,\n",
       " 0.05604544,\n",
       " 0.032862853,\n",
       " 0.1684109,\n",
       " 0.040072095,\n",
       " 0.24382862,\n",
       " 0.16294914,\n",
       " 0.116639234,\n",
       " 0.029534586,\n",
       " 0.29863188,\n",
       " 0.122500256,\n",
       " 0.031084938,\n",
       " 0.21855876,\n",
       " 0.014779304,\n",
       " 0.25025386,\n",
       " 0.022553496,\n",
       " 0.23571955,\n",
       " 0.06508482,\n",
       " 0.22837561,\n",
       " 0.16641656,\n",
       " 0.07868484,\n",
       " 0.07005213,\n",
       " 0.45534194,\n",
       " 0.03911149,\n",
       " 0.9362186,\n",
       " 0.038083434,\n",
       " 0.11099077,\n",
       " 0.8148115,\n",
       " 0.029741602,\n",
       " 0.14476615,\n",
       " 0.23920414,\n",
       " 0.03324935,\n",
       " 0.2995221,\n",
       " 0.03532118,\n",
       " 0.48932123,\n",
       " 0.071566515,\n",
       " 0.7598992,\n",
       " 0.15726131,\n",
       " 0.055648524,\n",
       " 0.0649926,\n",
       " 0.26600122,\n",
       " 0.067154855,\n",
       " 0.3882489,\n",
       " 0.4823602,\n",
       " 0.6895144,\n",
       " 0.19362338,\n",
       " 0.007703429,\n",
       " 0.34583712,\n",
       " 0.082383014,\n",
       " 0.058819782,\n",
       " 0.56164414,\n",
       " 0.014322322,\n",
       " 0.043476008,\n",
       " 0.031776663,\n",
       " 0.20438352,\n",
       " 0.278851,\n",
       " 0.56452024,\n",
       " 0.033032555,\n",
       " 0.51926523,\n",
       " 0.08116855,\n",
       " 0.7266709,\n",
       " 0.03343506,\n",
       " 0.0244955,\n",
       " 0.07435876,\n",
       " 0.040073644,\n",
       " 0.09858293,\n",
       " 0.69683355,\n",
       " 0.76938385,\n",
       " 0.02702097,\n",
       " 0.014259021,\n",
       " 0.65423083,\n",
       " 0.03005574,\n",
       " 0.8285703,\n",
       " 0.14263351,\n",
       " 0.35614422,\n",
       " 0.6447665,\n",
       " 0.31807458,\n",
       " 0.19878109,\n",
       " 0.20346391,\n",
       " 0.35560915,\n",
       " 0.059808526,\n",
       " 0.037465565,\n",
       " 0.383002,\n",
       " 0.119484864,\n",
       " 0.016305184,\n",
       " 0.21594478,\n",
       " 0.08698446,\n",
       " 0.08794314,\n",
       " 0.124562845,\n",
       " 0.021103526,\n",
       " 0.078091726,\n",
       " 0.18785492,\n",
       " 0.034125358,\n",
       " 0.17739591,\n",
       " 0.01753571,\n",
       " 0.47563258,\n",
       " 0.030373406,\n",
       " 0.09377857,\n",
       " 0.25951535,\n",
       " 0.049924996,\n",
       " 0.27821368,\n",
       " 0.692083,\n",
       " 0.20632933,\n",
       " 0.087420434,\n",
       " 0.14346166,\n",
       " 0.073904544,\n",
       " 0.028933702,\n",
       " 0.022722198,\n",
       " 0.033368137,\n",
       " 0.08573955,\n",
       " 0.030730743,\n",
       " 0.02972938,\n",
       " 0.014561352,\n",
       " 0.42782345,\n",
       " 0.6571949,\n",
       " 0.02849181,\n",
       " 0.027435299,\n",
       " 0.088681154,\n",
       " 0.21323863,\n",
       " 0.07391388,\n",
       " 0.48172793,\n",
       " 0.014205249,\n",
       " 0.19054762,\n",
       " 0.015116871,\n",
       " 0.026405284,\n",
       " 0.08363139,\n",
       " 0.15312867,\n",
       " 0.03990278,\n",
       " 0.23441027,\n",
       " 0.21428436,\n",
       " 0.14438328,\n",
       " 0.031519882,\n",
       " 0.54309136,\n",
       " 0.07051538,\n",
       " 0.015032572,\n",
       " 0.20965981,\n",
       " 0.2805768,\n",
       " 0.052282326,\n",
       " ...]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predict(test_dl, ff_with4_model)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['Exited'] = preds\n",
    "sub_df.to_csv('bank-churn-data/sub3.csv',index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "class FFWith5LayerModel(BaseModel):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.linear1 = nn.Linear(17, 64)\n",
    "        self.linear2 = nn.Linear(64, 128)\n",
    "        self.linear3 = nn.Linear(128, 64)\n",
    "        self.linear4 = nn.Linear(64, 32)\n",
    "        self.linear5 = nn.Linear(32, 1)\n",
    "    \n",
    "    def forward(self, xb):\n",
    "        out = self.linear1(xb)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear3(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear4(out)\n",
    "        out = F.relu(out)\n",
    "        out = self.linear5(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "ff_with5_model = FFWith5LayerModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'val_loss': 0.6803122398465179, 'val_acc': 0.7884256013451892}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history = [evaluate(ff_with5_model, val_dl)]\n",
    "history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val_loss: 0.516082, val_acc: 0.724184\n",
      "Epoch 1, val_loss: 0.367781, val_acc: 0.836388\n",
      "Epoch 2, val_loss: 0.371466, val_acc: 0.837735\n",
      "Epoch 3, val_loss: 0.363518, val_acc: 0.839598\n"
     ]
    }
   ],
   "source": [
    "history += fit(4, 0.2, ff_with5_model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val_loss: 0.365369, val_acc: 0.838601\n",
      "Epoch 1, val_loss: 0.363610, val_acc: 0.839625\n",
      "Epoch 2, val_loss: 0.373678, val_acc: 0.831449\n",
      "Epoch 3, val_loss: 0.364298, val_acc: 0.839613\n"
     ]
    }
   ],
   "source": [
    "history += fit(4, 0.1, ff_with5_model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0, val_loss: 0.361994, val_acc: 0.840857\n",
      "Epoch 1, val_loss: 0.361846, val_acc: 0.840521\n",
      "Epoch 2, val_loss: 0.361950, val_acc: 0.840597\n",
      "Epoch 3, val_loss: 0.361878, val_acc: 0.840679\n",
      "Epoch 4, val_loss: 0.361841, val_acc: 0.840966\n",
      "Epoch 5, val_loss: 0.361747, val_acc: 0.840972\n",
      "Epoch 6, val_loss: 0.362388, val_acc: 0.840815\n",
      "Epoch 7, val_loss: 0.361725, val_acc: 0.840688\n"
     ]
    }
   ],
   "source": [
    "history += fit(8, 0.02, ff_with5_model, train_dl, val_dl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.017368143,\n",
       " 0.674518,\n",
       " 0.080599196,\n",
       " 0.45374426,\n",
       " 0.51657325,\n",
       " 0.039768185,\n",
       " 0.012568688,\n",
       " 0.025300419,\n",
       " 0.30520895,\n",
       " 0.009973136,\n",
       " 0.23646533,\n",
       " 0.033130467,\n",
       " 0.010841757,\n",
       " 0.32679722,\n",
       " 0.56813955,\n",
       " 0.025970966,\n",
       " 0.086183846,\n",
       " 0.71194667,\n",
       " 0.026628783,\n",
       " 0.2224446,\n",
       " 0.040974785,\n",
       " 0.17926924,\n",
       " 0.45933867,\n",
       " 0.013626237,\n",
       " 0.7533729,\n",
       " 0.22639117,\n",
       " 0.7126588,\n",
       " 0.30928406,\n",
       " 0.2184384,\n",
       " 0.34596804,\n",
       " 0.04088821,\n",
       " 0.041841406,\n",
       " 0.24785058,\n",
       " 0.22019461,\n",
       " 0.07644065,\n",
       " 0.02297487,\n",
       " 0.6533794,\n",
       " 0.09205368,\n",
       " 0.20482522,\n",
       " 0.74085563,\n",
       " 0.6784341,\n",
       " 0.23127358,\n",
       " 0.11878197,\n",
       " 0.011565358,\n",
       " 0.668313,\n",
       " 0.09888513,\n",
       " 0.026797073,\n",
       " 0.022352654,\n",
       " 0.0069210296,\n",
       " 0.5565443,\n",
       " 0.13504162,\n",
       " 0.012553825,\n",
       " 0.016069314,\n",
       " 0.4399982,\n",
       " 0.033200264,\n",
       " 0.28308898,\n",
       " 0.21538335,\n",
       " 0.013970107,\n",
       " 0.027635204,\n",
       " 0.39999512,\n",
       " 0.015741594,\n",
       " 0.020619899,\n",
       " 0.26983118,\n",
       " 0.34640625,\n",
       " 0.013597836,\n",
       " 0.027796905,\n",
       " 0.57354426,\n",
       " 0.05391004,\n",
       " 0.1487234,\n",
       " 0.03848402,\n",
       " 0.4985635,\n",
       " 0.5295539,\n",
       " 0.52895826,\n",
       " 0.0495957,\n",
       " 0.016886147,\n",
       " 0.71514046,\n",
       " 0.2118446,\n",
       " 0.0777465,\n",
       " 0.090946555,\n",
       " 0.0409447,\n",
       " 0.036887605,\n",
       " 0.036767744,\n",
       " 0.57808006,\n",
       " 0.060012866,\n",
       " 0.5019155,\n",
       " 0.09442915,\n",
       " 0.20629652,\n",
       " 0.091635175,\n",
       " 0.19066617,\n",
       " 0.10816871,\n",
       " 0.38500714,\n",
       " 0.0775657,\n",
       " 0.07605891,\n",
       " 0.012465686,\n",
       " 0.012747619,\n",
       " 0.01424737,\n",
       " 0.97110546,\n",
       " 0.035491064,\n",
       " 0.43510845,\n",
       " 0.22999057,\n",
       " 0.02378954,\n",
       " 0.09928691,\n",
       " 0.006789536,\n",
       " 0.6820216,\n",
       " 0.43242368,\n",
       " 0.72496134,\n",
       " 0.053813297,\n",
       " 0.080718786,\n",
       " 0.013319387,\n",
       " 0.24250448,\n",
       " 0.4053729,\n",
       " 0.45077708,\n",
       " 0.39260653,\n",
       " 0.053235795,\n",
       " 0.10570684,\n",
       " 0.027829435,\n",
       " 0.014506891,\n",
       " 0.20213248,\n",
       " 0.31511992,\n",
       " 0.049136158,\n",
       " 0.05199114,\n",
       " 0.02502314,\n",
       " 0.01155803,\n",
       " 0.027712906,\n",
       " 0.22075047,\n",
       " 0.22167745,\n",
       " 0.0314088,\n",
       " 0.036207616,\n",
       " 0.7364183,\n",
       " 0.027302613,\n",
       " 0.03044009,\n",
       " 0.30809522,\n",
       " 0.7263594,\n",
       " 0.075307444,\n",
       " 0.062271953,\n",
       " 0.1539036,\n",
       " 0.15757248,\n",
       " 0.011184299,\n",
       " 0.37944365,\n",
       " 0.27042612,\n",
       " 0.023289727,\n",
       " 0.09986715,\n",
       " 0.03831087,\n",
       " 0.013432576,\n",
       " 0.21473996,\n",
       " 0.7070563,\n",
       " 0.06336797,\n",
       " 0.5537268,\n",
       " 0.36152396,\n",
       " 0.036806054,\n",
       " 0.04374027,\n",
       " 0.041828983,\n",
       " 0.023489598,\n",
       " 0.9168689,\n",
       " 0.7088455,\n",
       " 0.025276424,\n",
       " 0.01802972,\n",
       " 0.266607,\n",
       " 0.23963796,\n",
       " 0.029537402,\n",
       " 0.17161313,\n",
       " 0.06346121,\n",
       " 0.38222936,\n",
       " 0.7294396,\n",
       " 0.43884638,\n",
       " 0.082753085,\n",
       " 0.71075475,\n",
       " 0.68819624,\n",
       " 0.68824756,\n",
       " 0.3515105,\n",
       " 0.6338119,\n",
       " 0.032815967,\n",
       " 0.33001032,\n",
       " 0.09727104,\n",
       " 0.035209265,\n",
       " 0.28121078,\n",
       " 0.047770243,\n",
       " 0.5163444,\n",
       " 0.08333732,\n",
       " 0.013083075,\n",
       " 0.6104828,\n",
       " 0.48070025,\n",
       " 0.04375439,\n",
       " 0.011281961,\n",
       " 0.013332178,\n",
       " 0.7214079,\n",
       " 0.44394475,\n",
       " 0.061785758,\n",
       " 0.28776905,\n",
       " 0.25318953,\n",
       " 0.052837178,\n",
       " 0.587387,\n",
       " 0.51058,\n",
       " 0.21868655,\n",
       " 0.32172623,\n",
       " 0.047698744,\n",
       " 0.8704875,\n",
       " 0.01098369,\n",
       " 0.0057274057,\n",
       " 0.0815324,\n",
       " 0.16228554,\n",
       " 0.029351175,\n",
       " 0.5782353,\n",
       " 0.010998493,\n",
       " 0.25016984,\n",
       " 0.028441297,\n",
       " 0.012187197,\n",
       " 0.01601721,\n",
       " 0.36037824,\n",
       " 0.052638363,\n",
       " 0.66618943,\n",
       " 0.011707031,\n",
       " 0.1441895,\n",
       " 0.022232424,\n",
       " 0.037222635,\n",
       " 0.3977988,\n",
       " 0.029174503,\n",
       " 0.01344498,\n",
       " 0.5790419,\n",
       " 0.14872698,\n",
       " 0.04417622,\n",
       " 0.22034805,\n",
       " 0.37387782,\n",
       " 0.08145717,\n",
       " 0.57179105,\n",
       " 0.6747589,\n",
       " 0.44647023,\n",
       " 0.5835699,\n",
       " 0.20958988,\n",
       " 0.011427363,\n",
       " 0.040257458,\n",
       " 0.019978762,\n",
       " 0.005302571,\n",
       " 0.34230554,\n",
       " 0.28169778,\n",
       " 0.38582304,\n",
       " 0.5059465,\n",
       " 0.0953892,\n",
       " 0.92260724,\n",
       " 0.042347066,\n",
       " 0.0941403,\n",
       " 0.20946015,\n",
       " 0.1429981,\n",
       " 0.714032,\n",
       " 0.647448,\n",
       " 0.13949454,\n",
       " 0.045772284,\n",
       " 0.024445808,\n",
       " 0.08228222,\n",
       " 0.012530546,\n",
       " 0.45567003,\n",
       " 0.1461409,\n",
       " 0.07728303,\n",
       " 0.036389414,\n",
       " 0.031199804,\n",
       " 0.04506996,\n",
       " 0.012688141,\n",
       " 0.026012098,\n",
       " 0.14577796,\n",
       " 0.74433184,\n",
       " 0.013295733,\n",
       " 0.4128593,\n",
       " 0.08673962,\n",
       " 0.07397342,\n",
       " 0.02758182,\n",
       " 0.012161489,\n",
       " 0.7069617,\n",
       " 0.07678196,\n",
       " 0.6749039,\n",
       " 0.08840418,\n",
       " 0.00784811,\n",
       " 0.012065046,\n",
       " 0.052503586,\n",
       " 0.20783745,\n",
       " 0.042742766,\n",
       " 0.48152775,\n",
       " 0.23988023,\n",
       " 0.15243736,\n",
       " 0.47506282,\n",
       " 0.042157587,\n",
       " 0.058235224,\n",
       " 0.085828125,\n",
       " 0.26775444,\n",
       " 0.0071164677,\n",
       " 0.4880061,\n",
       " 0.25432482,\n",
       " 0.049004182,\n",
       " 0.12780523,\n",
       " 0.045892358,\n",
       " 0.03544584,\n",
       " 0.027240613,\n",
       " 0.38444105,\n",
       " 0.5962652,\n",
       " 0.23485583,\n",
       " 0.031016998,\n",
       " 0.030573139,\n",
       " 0.24102813,\n",
       " 0.02768577,\n",
       " 0.70055604,\n",
       " 0.02211251,\n",
       " 0.014316849,\n",
       " 0.040316124,\n",
       " 0.083033696,\n",
       " 0.26977926,\n",
       " 0.51115376,\n",
       " 0.35216367,\n",
       " 0.09796765,\n",
       " 0.012392284,\n",
       " 0.046704233,\n",
       " 0.006120533,\n",
       " 0.09383895,\n",
       " 0.07507264,\n",
       " 0.7274286,\n",
       " 0.44419715,\n",
       " 0.07269456,\n",
       " 0.08732718,\n",
       " 0.011636936,\n",
       " 0.24197616,\n",
       " 0.04039743,\n",
       " 0.016624596,\n",
       " 0.17979817,\n",
       " 0.063035846,\n",
       " 0.030415276,\n",
       " 0.07924551,\n",
       " 0.14692478,\n",
       " 0.03345736,\n",
       " 0.7565291,\n",
       " 0.08902654,\n",
       " 0.2990999,\n",
       " 0.18972674,\n",
       " 0.029877644,\n",
       " 0.90707874,\n",
       " 0.011934017,\n",
       " 0.1138815,\n",
       " 0.1462258,\n",
       " 0.73730737,\n",
       " 0.043830745,\n",
       " 0.006352443,\n",
       " 0.14466178,\n",
       " 0.037326675,\n",
       " 0.46582317,\n",
       " 0.023555938,\n",
       " 0.035437036,\n",
       " 0.0066571464,\n",
       " 0.33643886,\n",
       " 0.053980913,\n",
       " 0.3003221,\n",
       " 0.027048972,\n",
       " 0.012841443,\n",
       " 0.021985969,\n",
       " 0.07338747,\n",
       " 0.28759804,\n",
       " 0.3042731,\n",
       " 0.021497829,\n",
       " 0.5171183,\n",
       " 0.1049742,\n",
       " 0.36435825,\n",
       " 0.012826122,\n",
       " 0.06792674,\n",
       " 0.11288653,\n",
       " 0.21666436,\n",
       " 0.010459562,\n",
       " 0.07391997,\n",
       " 0.03253242,\n",
       " 0.6187902,\n",
       " 0.08831395,\n",
       " 0.09597024,\n",
       " 0.19379106,\n",
       " 0.15236755,\n",
       " 0.028379934,\n",
       " 0.08975757,\n",
       " 0.5094337,\n",
       " 0.058581073,\n",
       " 0.10298881,\n",
       " 0.0913444,\n",
       " 0.012789833,\n",
       " 0.012884151,\n",
       " 0.011246082,\n",
       " 0.058407634,\n",
       " 0.013523998,\n",
       " 0.027441576,\n",
       " 0.09847946,\n",
       " 0.72672004,\n",
       " 0.0115053505,\n",
       " 0.027926212,\n",
       " 0.67962813,\n",
       " 0.07274242,\n",
       " 0.12915413,\n",
       " 0.021915885,\n",
       " 0.028352926,\n",
       " 0.017581848,\n",
       " 0.71225756,\n",
       " 0.08014643,\n",
       " 0.096077845,\n",
       " 0.5491242,\n",
       " 0.4350332,\n",
       " 0.095175624,\n",
       " 0.07592839,\n",
       " 0.07788347,\n",
       " 0.7505722,\n",
       " 0.6836854,\n",
       " 0.34748387,\n",
       " 0.31735566,\n",
       " 0.01394218,\n",
       " 0.010494774,\n",
       " 0.085688,\n",
       " 0.74836653,\n",
       " 0.54279023,\n",
       " 0.03688924,\n",
       " 0.015258527,\n",
       " 0.08825494,\n",
       " 0.10755828,\n",
       " 0.12624997,\n",
       " 0.012374614,\n",
       " 0.0818279,\n",
       " 0.011886802,\n",
       " 0.034284037,\n",
       " 0.021200871,\n",
       " 0.522951,\n",
       " 0.07909241,\n",
       " 0.30604294,\n",
       " 0.08286112,\n",
       " 0.51612186,\n",
       " 0.71158564,\n",
       " 0.020925358,\n",
       " 0.034865078,\n",
       " 0.04054327,\n",
       " 0.035915345,\n",
       " 0.08442309,\n",
       " 0.11089108,\n",
       " 0.15038462,\n",
       " 0.81778914,\n",
       " 0.02218787,\n",
       " 0.14598966,\n",
       " 0.25820306,\n",
       " 0.13783345,\n",
       " 0.15532553,\n",
       " 0.33460504,\n",
       " 0.013019031,\n",
       " 0.07664367,\n",
       " 0.43493813,\n",
       " 0.08968026,\n",
       " 0.20939182,\n",
       " 0.20610106,\n",
       " 0.1400094,\n",
       " 0.41809577,\n",
       " 0.06528613,\n",
       " 0.7078993,\n",
       " 0.020572316,\n",
       " 0.12800744,\n",
       " 0.036520343,\n",
       " 0.46197945,\n",
       " 0.20774697,\n",
       " 0.07773519,\n",
       " 0.08156438,\n",
       " 0.034494743,\n",
       " 0.05100653,\n",
       " 0.08264852,\n",
       " 0.19097678,\n",
       " 0.21949562,\n",
       " 0.014715209,\n",
       " 0.2000535,\n",
       " 0.104991436,\n",
       " 0.18816863,\n",
       " 0.12801838,\n",
       " 0.018781051,\n",
       " 0.012707755,\n",
       " 0.16224132,\n",
       " 0.013341414,\n",
       " 0.011638861,\n",
       " 0.6999297,\n",
       " 0.54464483,\n",
       " 0.02799991,\n",
       " 0.30762893,\n",
       " 0.1325067,\n",
       " 0.48929518,\n",
       " 0.69178003,\n",
       " 0.08024738,\n",
       " 0.07246726,\n",
       " 0.09707863,\n",
       " 0.4688867,\n",
       " 0.009625272,\n",
       " 0.07608861,\n",
       " 0.14842543,\n",
       " 0.028105037,\n",
       " 0.3165868,\n",
       " 0.15599073,\n",
       " 0.0294991,\n",
       " 0.025640426,\n",
       " 0.16187355,\n",
       " 0.048354205,\n",
       " 0.20970528,\n",
       " 0.42355248,\n",
       " 0.55634844,\n",
       " 0.01966656,\n",
       " 0.083157435,\n",
       " 0.2580455,\n",
       " 0.07110993,\n",
       " 0.13632974,\n",
       " 0.036622826,\n",
       " 0.27913883,\n",
       " 0.05306211,\n",
       " 0.032010168,\n",
       " 0.045023117,\n",
       " 0.2925906,\n",
       " 0.110927805,\n",
       " 0.034710404,\n",
       " 0.38668838,\n",
       " 0.020866677,\n",
       " 0.042342667,\n",
       " 0.014076215,\n",
       " 0.08067669,\n",
       " 0.094267815,\n",
       " 0.039147824,\n",
       " 0.02914718,\n",
       " 0.11497942,\n",
       " 0.21073233,\n",
       " 0.008141257,\n",
       " 0.04248472,\n",
       " 0.69456404,\n",
       " 0.03303818,\n",
       " 0.14493439,\n",
       " 0.16387343,\n",
       " 0.026240183,\n",
       " 0.020161586,\n",
       " 0.005632783,\n",
       " 0.13051516,\n",
       " 0.37625924,\n",
       " 0.40765095,\n",
       " 0.23583183,\n",
       " 0.39124212,\n",
       " 0.1347182,\n",
       " 0.11309403,\n",
       " 0.3420689,\n",
       " 0.11323896,\n",
       " 0.16092366,\n",
       " 0.0633137,\n",
       " 0.012361258,\n",
       " 0.6830929,\n",
       " 0.07648304,\n",
       " 0.07032185,\n",
       " 0.4184533,\n",
       " 0.006259507,\n",
       " 0.033941325,\n",
       " 0.65636975,\n",
       " 0.26079872,\n",
       " 0.023148024,\n",
       " 0.22898495,\n",
       " 0.7346727,\n",
       " 0.17668326,\n",
       " 0.020361291,\n",
       " 0.74537873,\n",
       " 0.38836548,\n",
       " 0.012718415,\n",
       " 0.20898607,\n",
       " 0.17784011,\n",
       " 0.28933555,\n",
       " 0.50062567,\n",
       " 0.010297637,\n",
       " 0.006468422,\n",
       " 0.1075359,\n",
       " 0.056286007,\n",
       " 0.014497638,\n",
       " 0.023666173,\n",
       " 0.15223077,\n",
       " 0.30438036,\n",
       " 0.008991987,\n",
       " 0.01126747,\n",
       " 0.013157163,\n",
       " 0.42089435,\n",
       " 0.016299885,\n",
       " 0.081756115,\n",
       " 0.033279724,\n",
       " 0.7714537,\n",
       " 0.33246413,\n",
       " 0.4856533,\n",
       " 0.23212917,\n",
       " 0.09048341,\n",
       " 0.01672057,\n",
       " 0.17154132,\n",
       " 0.1776381,\n",
       " 0.55440444,\n",
       " 0.07781594,\n",
       " 0.110159464,\n",
       " 0.27304086,\n",
       " 0.55258477,\n",
       " 0.08443812,\n",
       " 0.014480779,\n",
       " 0.01407599,\n",
       " 0.012369755,\n",
       " 0.014956067,\n",
       " 0.14310923,\n",
       " 0.046646062,\n",
       " 0.14240997,\n",
       " 0.011331379,\n",
       " 0.2753243,\n",
       " 0.15572214,\n",
       " 0.0243237,\n",
       " 0.06620991,\n",
       " 0.07550362,\n",
       " 0.006349945,\n",
       " 0.21865043,\n",
       " 0.055817496,\n",
       " 0.03683207,\n",
       " 0.077551045,\n",
       " 0.063381016,\n",
       " 0.4745042,\n",
       " 0.028071426,\n",
       " 0.05744866,\n",
       " 0.17500083,\n",
       " 0.007257815,\n",
       " 0.15062681,\n",
       " 0.007851167,\n",
       " 0.012790857,\n",
       " 0.44332236,\n",
       " 0.011969746,\n",
       " 0.44566056,\n",
       " 0.043538675,\n",
       " 0.121371366,\n",
       " 0.20942558,\n",
       " 0.023897152,\n",
       " 0.056175776,\n",
       " 0.35801166,\n",
       " 0.75037545,\n",
       " 0.20902656,\n",
       " 0.69505847,\n",
       " 0.1498438,\n",
       " 0.678502,\n",
       " 0.5959801,\n",
       " 0.069230534,\n",
       " 0.055904478,\n",
       " 0.033359934,\n",
       " 0.17055345,\n",
       " 0.068313204,\n",
       " 0.029886736,\n",
       " 0.3553772,\n",
       " 0.008332365,\n",
       " 0.01914006,\n",
       " 0.15363057,\n",
       " 0.6870702,\n",
       " 0.6450734,\n",
       " 0.15269202,\n",
       " 0.6231008,\n",
       " 0.031253885,\n",
       " 0.38654524,\n",
       " 0.0120102875,\n",
       " 0.03585019,\n",
       " 0.30019245,\n",
       " 0.013029789,\n",
       " 0.094540894,\n",
       " 0.25375652,\n",
       " 0.13428546,\n",
       " 0.023103429,\n",
       " 0.19802484,\n",
       " 0.57855076,\n",
       " 0.011727091,\n",
       " 0.08727794,\n",
       " 0.006561678,\n",
       " 0.15161306,\n",
       " 0.012975357,\n",
       " 0.033372577,\n",
       " 0.012041985,\n",
       " 0.28810146,\n",
       " 0.011825329,\n",
       " 0.10569994,\n",
       " 0.2029335,\n",
       " 0.2022655,\n",
       " 0.7031825,\n",
       " 0.2294702,\n",
       " 0.3353322,\n",
       " 0.0071774498,\n",
       " 0.03328096,\n",
       " 0.37920064,\n",
       " 0.0136905145,\n",
       " 0.14021595,\n",
       " 0.095500976,\n",
       " 0.032230586,\n",
       " 0.008749308,\n",
       " 0.014935021,\n",
       " 0.0776972,\n",
       " 0.65032375,\n",
       " 0.010067883,\n",
       " 0.718331,\n",
       " 0.6601027,\n",
       " 0.08828509,\n",
       " 0.015713727,\n",
       " 0.08212296,\n",
       " 0.24815084,\n",
       " 0.24930966,\n",
       " 0.023034388,\n",
       " 0.8834008,\n",
       " 0.021705564,\n",
       " 0.32846692,\n",
       " 0.12738283,\n",
       " 0.024457887,\n",
       " 0.27516967,\n",
       " 0.073814034,\n",
       " 0.19953485,\n",
       " 0.31755003,\n",
       " 0.07367132,\n",
       " 0.15679634,\n",
       " 0.012945157,\n",
       " 0.34924302,\n",
       " 0.65997976,\n",
       " 0.023518637,\n",
       " 0.26927367,\n",
       " 0.592712,\n",
       " 0.0653072,\n",
       " 0.122656435,\n",
       " 0.19602266,\n",
       " 0.029721182,\n",
       " 0.083213985,\n",
       " 0.42192915,\n",
       " 0.011625123,\n",
       " 0.65757346,\n",
       " 0.46817562,\n",
       " 0.07967904,\n",
       " 0.31537938,\n",
       " 0.08026641,\n",
       " 0.4138298,\n",
       " 0.2414635,\n",
       " 0.08134689,\n",
       " 0.2427421,\n",
       " 0.13463704,\n",
       " 0.13426809,\n",
       " 0.109663725,\n",
       " 0.1514316,\n",
       " 0.69384366,\n",
       " 0.6687656,\n",
       " 0.4107447,\n",
       " 0.10244077,\n",
       " 0.680118,\n",
       " 0.09507123,\n",
       " 0.12424828,\n",
       " 0.6258767,\n",
       " 0.13682006,\n",
       " 0.14886703,\n",
       " 0.1558858,\n",
       " 0.20982763,\n",
       " 0.017159281,\n",
       " 0.01756489,\n",
       " 0.037613165,\n",
       " 0.23287812,\n",
       " 0.15079775,\n",
       " 0.13820043,\n",
       " 0.045254465,\n",
       " 0.2765763,\n",
       " 0.14870235,\n",
       " 0.039307278,\n",
       " 0.7458354,\n",
       " 0.68028516,\n",
       " 0.049727112,\n",
       " 0.123236746,\n",
       " 0.011223924,\n",
       " 0.043851834,\n",
       " 0.33343375,\n",
       " 0.64266574,\n",
       " 0.0414084,\n",
       " 0.06684877,\n",
       " 0.08834882,\n",
       " 0.040727638,\n",
       " 0.39383367,\n",
       " 0.033852853,\n",
       " 0.0117527,\n",
       " 0.07547866,\n",
       " 0.1722079,\n",
       " 0.088695586,\n",
       " 0.26793078,\n",
       " 0.009818524,\n",
       " 0.083715625,\n",
       " 0.10843184,\n",
       " 0.7072461,\n",
       " 0.0062076077,\n",
       " 0.012410331,\n",
       " 0.45749888,\n",
       " 0.1945725,\n",
       " 0.060339656,\n",
       " 0.077393375,\n",
       " 0.6626456,\n",
       " 0.373419,\n",
       " 0.03313499,\n",
       " 0.013885053,\n",
       " 0.01319011,\n",
       " 0.011180551,\n",
       " 0.3190028,\n",
       " 0.7656048,\n",
       " 0.109643266,\n",
       " 0.23783937,\n",
       " 0.08708537,\n",
       " 0.021052785,\n",
       " 0.18738599,\n",
       " 0.3351407,\n",
       " 0.030774668,\n",
       " 0.5211842,\n",
       " 0.00645007,\n",
       " 0.7256303,\n",
       " 0.4944163,\n",
       " 0.22207852,\n",
       " 0.036545485,\n",
       " 0.020443497,\n",
       " 0.18723363,\n",
       " 0.24044791,\n",
       " 0.015730672,\n",
       " 0.109918535,\n",
       " 0.016380936,\n",
       " 0.30525067,\n",
       " 0.03705002,\n",
       " 0.036270935,\n",
       " 0.030780535,\n",
       " 0.113600194,\n",
       " 0.041507598,\n",
       " 0.18562,\n",
       " 0.029998852,\n",
       " 0.0059955115,\n",
       " 0.027972057,\n",
       " 0.6379712,\n",
       " 0.13132659,\n",
       " 0.11129921,\n",
       " 0.68873864,\n",
       " 0.012969453,\n",
       " 0.12248406,\n",
       " 0.028919183,\n",
       " 0.027972648,\n",
       " 0.3226895,\n",
       " 0.07767124,\n",
       " 0.007722066,\n",
       " 0.01251812,\n",
       " 0.08677202,\n",
       " 0.0065219956,\n",
       " 0.013653465,\n",
       " 0.09541534,\n",
       " 0.1193408,\n",
       " 0.07933635,\n",
       " 0.5658693,\n",
       " 0.042942204,\n",
       " 0.033632718,\n",
       " 0.8651858,\n",
       " 0.35064945,\n",
       " 0.45915627,\n",
       " 0.027830506,\n",
       " 0.027216224,\n",
       " 0.83859086,\n",
       " 0.2489226,\n",
       " 0.16328485,\n",
       " 0.105960846,\n",
       " 0.026027223,\n",
       " 0.1984016,\n",
       " 0.6935218,\n",
       " 0.6717545,\n",
       " 0.013437379,\n",
       " 0.6228516,\n",
       " 0.22675194,\n",
       " 0.006072734,\n",
       " 0.50015295,\n",
       " 0.70765483,\n",
       " 0.026811298,\n",
       " 0.2986545,\n",
       " 0.09589442,\n",
       " 0.02621952,\n",
       " 0.684259,\n",
       " 0.025554467,\n",
       " 0.034293495,\n",
       " 0.45426714,\n",
       " 0.055573687,\n",
       " 0.025344811,\n",
       " 0.15547052,\n",
       " 0.039646726,\n",
       " 0.23390281,\n",
       " 0.15103924,\n",
       " 0.12126842,\n",
       " 0.019955572,\n",
       " 0.28395522,\n",
       " 0.13825774,\n",
       " 0.024766313,\n",
       " 0.24898984,\n",
       " 0.012872755,\n",
       " 0.23515914,\n",
       " 0.01705665,\n",
       " 0.24839897,\n",
       " 0.055412907,\n",
       " 0.21610548,\n",
       " 0.17064536,\n",
       " 0.07216747,\n",
       " 0.08242702,\n",
       " 0.47386348,\n",
       " 0.0344081,\n",
       " 0.95015967,\n",
       " 0.034494095,\n",
       " 0.0889884,\n",
       " 0.81557584,\n",
       " 0.021780668,\n",
       " 0.15892223,\n",
       " 0.16483152,\n",
       " 0.027592784,\n",
       " 0.30902362,\n",
       " 0.0364796,\n",
       " 0.49218428,\n",
       " 0.084891245,\n",
       " 0.7707234,\n",
       " 0.1449272,\n",
       " 0.058288243,\n",
       " 0.04870649,\n",
       " 0.2754536,\n",
       " 0.0709599,\n",
       " 0.40786108,\n",
       " 0.50131476,\n",
       " 0.70481724,\n",
       " 0.20986202,\n",
       " 0.0073315953,\n",
       " 0.3092662,\n",
       " 0.07589285,\n",
       " 0.049353622,\n",
       " 0.57087386,\n",
       " 0.013402833,\n",
       " 0.045665238,\n",
       " 0.029707635,\n",
       " 0.21037632,\n",
       " 0.24367966,\n",
       " 0.57909894,\n",
       " 0.0278819,\n",
       " 0.47367242,\n",
       " 0.081307575,\n",
       " 0.73812896,\n",
       " 0.03167319,\n",
       " 0.021065358,\n",
       " 0.066275984,\n",
       " 0.037415635,\n",
       " 0.086479664,\n",
       " 0.70093757,\n",
       " 0.76684463,\n",
       " 0.02735884,\n",
       " 0.013218704,\n",
       " 0.6592926,\n",
       " 0.030218575,\n",
       " 0.83124137,\n",
       " 0.12137701,\n",
       " 0.3247864,\n",
       " 0.6517562,\n",
       " 0.34812027,\n",
       " 0.21914226,\n",
       " 0.22441012,\n",
       " 0.3289151,\n",
       " 0.05828746,\n",
       " 0.032643374,\n",
       " 0.32304534,\n",
       " 0.1171257,\n",
       " 0.016837193,\n",
       " 0.23404017,\n",
       " 0.07790218,\n",
       " 0.08079128,\n",
       " 0.1275012,\n",
       " 0.019931253,\n",
       " 0.07798971,\n",
       " 0.20679845,\n",
       " 0.03639249,\n",
       " 0.20081893,\n",
       " 0.011012485,\n",
       " 0.4861162,\n",
       " 0.028449781,\n",
       " 0.1011354,\n",
       " 0.26355207,\n",
       " 0.055275057,\n",
       " 0.29246715,\n",
       " 0.68678886,\n",
       " 0.23581736,\n",
       " 0.098090604,\n",
       " 0.13732187,\n",
       " 0.079716854,\n",
       " 0.026222678,\n",
       " 0.017024279,\n",
       " 0.038204532,\n",
       " 0.07876007,\n",
       " 0.028822169,\n",
       " 0.03383232,\n",
       " 0.015177263,\n",
       " 0.37866023,\n",
       " 0.6653196,\n",
       " 0.02997123,\n",
       " 0.028094279,\n",
       " 0.09479628,\n",
       " 0.17896457,\n",
       " 0.065778755,\n",
       " 0.483671,\n",
       " 0.013433645,\n",
       " 0.18219142,\n",
       " 0.010982621,\n",
       " 0.02691426,\n",
       " 0.08939048,\n",
       " 0.15269662,\n",
       " 0.037300766,\n",
       " 0.235686,\n",
       " 0.16027643,\n",
       " 0.13217546,\n",
       " 0.029578239,\n",
       " 0.55817187,\n",
       " 0.07160998,\n",
       " 0.011799196,\n",
       " 0.22879271,\n",
       " 0.29703462,\n",
       " 0.05288686,\n",
       " ...]"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "preds = predict(test_dl, ff_with5_model)\n",
    "preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "sub_df['Exited'] = preds\n",
    "sub_df.to_csv('bank-churn-data/sub4.csv',index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
